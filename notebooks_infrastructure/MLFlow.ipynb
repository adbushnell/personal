{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15606531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation\n",
    "# https://www.mlflow.org/docs/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c71e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import waitress\n",
    "from flask import Flask, request\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a409d37",
   "metadata": {},
   "source": [
    "# 1. Local Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac36135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = r'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(data_url, sep=';')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=123)\n",
    "\n",
    "# split\n",
    "label   = 'quality'\n",
    "X_train = df_train.drop(columns=label)\n",
    "y_train = df_train[label]\n",
    "X_test  = df_test.drop(columns=label)\n",
    "y_test  = df_test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred)) \n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    \n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up experiment\n",
    "\n",
    "mlruns_path = os.path.join(os.path.abspath('.'), 'mlruns')\n",
    "\n",
    "tracking_uri = f\"file:{mlruns_path}\"\n",
    "# Need to have mlruns as the folder name!\n",
    "\n",
    "experiment_name = 'Wine Quality - Elastic Net'\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "n_runs = 10\n",
    "max_alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "\n",
    "for run in range(n_runs):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # random hyperparameters\n",
    "        alpha = np.random.uniform(0, max_alpha)\n",
    "        l1_ratio = np.random.rand()\n",
    "\n",
    "        # model fitting\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # model evaluation\n",
    "        rmse_train, mae_train, r2_train = eval_metrics(y_train, model.predict(X_train))\n",
    "        rmse_test, mae_test, r2_test = eval_metrics(y_test, model.predict(X_test))\n",
    "\n",
    "        # Reporting\n",
    "        mlflow.log_param('alpha', alpha)\n",
    "        mlflow.log_param('l1_ratio', l1_ratio)\n",
    "        \n",
    "        mlflow.log_metric('rmse_train', rmse_train)\n",
    "        mlflow.log_metric('mae_train', mae_train)\n",
    "        mlflow.log_metric('r2_train', r2_train)\n",
    "        \n",
    "        mlflow.log_metric('rmse_test', rmse_test)\n",
    "        mlflow.log_metric('mae_test', mae_test)\n",
    "        mlflow.log_metric('r2_test', r2_test)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now go to the ui\n",
    "\n",
    "## in cmd: path = ..\\..\\notebooks (parent directory of mlruns)\n",
    "## in cmd: mlflow ui\n",
    "## in browser: go to localhost:5000 or http://127.0.0.1:5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf6c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d37106",
   "metadata": {},
   "source": [
    "# 2. Remote Tracking\n",
    "\n",
    "Not currently working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f23c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up experiment\n",
    "\n",
    "tracking_uri = r'http://52.90.101.28:5000/'\n",
    "# this one was made on AWS - doesnt exist now\n",
    "\n",
    "experiment_name = 'Wine Quality - Elastic Net'\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f40423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "n_runs = 10\n",
    "max_alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddea4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "\n",
    "for run in range(n_runs):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # random hyperparameters\n",
    "        alpha = np.random.uniform(0, max_alpha)\n",
    "        l1_ratio = np.random.rand()\n",
    "\n",
    "        # model fitting\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # model evaluation\n",
    "        rmse_train, mae_train, r2_train = eval_metrics(y_train, model.predict(X_train))\n",
    "        rmse_test, mae_test, r2_test = eval_metrics(y_test, model.predict(X_test))\n",
    "\n",
    "        # Reporting\n",
    "        mlflow.log_param('alpha', alpha)\n",
    "        mlflow.log_param('l1_ratio', l1_ratio)\n",
    "        \n",
    "        mlflow.log_metric('rmse_train', rmse_train)\n",
    "        mlflow.log_metric('mae_train', mae_train)\n",
    "        mlflow.log_metric('r2_train', r2_train)\n",
    "        \n",
    "        mlflow.log_metric('rmse_test', rmse_test)\n",
    "        mlflow.log_metric('mae_test', mae_test)\n",
    "        mlflow.log_metric('r2_test', r2_test)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843fa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a0072cb",
   "metadata": {},
   "source": [
    "# 3. Local Server Artifact Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fed01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:C:\\\\Users\\\\Dell5520\\\\PycharmProjects\\\\personal\\\\infrastructure\\\\notebooks\\\\mlruns/0', experiment_id='0', lifecycle_stage='active', name='Wine Quality - Elastic Net', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up experiment\n",
    "\n",
    "mlruns_path = os.path.join(os.path.abspath('.'), 'mlruns')\n",
    "\n",
    "tracking_uri = f\"file:{mlruns_path}\"\n",
    "# Need to have mlruns as the folder name!\n",
    "\n",
    "experiment_name = 'Wine Quality - Elastic Net'\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f66d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file mlflow_artifacts already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir mlflow_artifacts\n",
    "\n",
    "destination_path = os.path.join(os.path.abspath('.'), 'mlflow_artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35caa4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dell5520\\\\PycharmProjects\\\\personal\\\\infrastructure\\\\notebooks\\\\mlflow_artifacts\\\\model'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our metric\n",
    "metric = r'rmse_test'\n",
    "\n",
    "# connect to our client\n",
    "client = mlflow.tracking.MlflowClient(tracking_uri=tracking_uri)\n",
    "\n",
    "# get experiment id\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# model runs\n",
    "runs = client.search_runs(experiment_id, order_by=[f'metrics.{metric}'])\n",
    "\n",
    "# get best run ID\n",
    "best_run_id = runs[0].info.run_id\n",
    "\n",
    "# download artifacts\n",
    "client.download_artifacts(best_run_id, 'model', destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeefc199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 33.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# make a function\n",
    "\n",
    "def download_top_models(\n",
    "    n, metric, tracking_uri, experiment_name, destination_path, model_name\n",
    "):\n",
    "    \n",
    "    # connect to our client\n",
    "    client = mlflow.tracking.MlflowClient(tracking_uri=tracking_uri)\n",
    "\n",
    "    # get experiment id\n",
    "    experiment_id = client.get_experiment_by_name(\n",
    "        experiment_name\n",
    "    ).experiment_id\n",
    "\n",
    "    # model runs\n",
    "    runs = client.search_runs(experiment_id, order_by=[f'metrics.{metric}'])\n",
    "    \n",
    "    run_ids = [run.info.run_id for run in runs[0:n]]\n",
    "    \n",
    "    for ind, run in tqdm(enumerate(run_ids)):\n",
    "        \n",
    "        model_path = os.path.join(destination_path, str(ind + 1))\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            os.mkdir(model_path)\n",
    "        \n",
    "        client.download_artifacts(\n",
    "            run, f'{model_name}', model_path\n",
    "        )\n",
    "        \n",
    "n = 10\n",
    "metric = r'rmse_test'\n",
    "model_name = 'model' # has to match what you log model as \n",
    "\n",
    "download_top_models(\n",
    "    n, metric, tracking_uri, experiment_name, destination_path, model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out runs as a df\n",
    "\n",
    "df_runs = pd.DataFrame([{**i.data.metrics, **i.data.params, **dict(i.info)} for i in runs])\n",
    "df_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model_uri = os.path.join(destination_path, 'model')\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "print(model)\n",
    "\n",
    "# Predicting to make sure it works\n",
    "model.predict(np.zeros((1, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e293cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f331c8d7",
   "metadata": {},
   "source": [
    "# 4. MLFlow & Flask\n",
    "\n",
    "- Before running these cells, run the cells in the MLFlow Flask App notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9ce0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try get request - status code 200 is good\n",
    "requests.get('http://127.0.0.1:1337/echo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4029b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Try a post request\n",
    "r = requests.post('http://127.0.0.1:1337/echo', data='hello')\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c71d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data to make predictions on\n",
    "data_url = r'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = json.dumps(pd.read_csv(data_url, sep=';').drop(columns='quality').sample(10).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67dcc547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  b'[5.650008902645847, 5.218801183986223, 5.444273831423893, 5.249585737472442, 5.526233529506899, 5.801264277374394, 5.546808439626528, 6.39625542879018, 5.693060101690762, 5.665863509768949]'\n"
     ]
    }
   ],
   "source": [
    "# Doing a post request to get predictions\n",
    "r = requests.post('http://127.0.0.1:1337/invocations', data=data)\n",
    "print('Content: ', r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b9da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
